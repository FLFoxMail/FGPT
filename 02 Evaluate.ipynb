{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**性能评估**\n",
    "本节将搭建性能评估环境，并对初始模型的性能指标进行验证，包括单卡吞吐量（tokens/s）和显存占用（GB）等。具体涵盖以下几个方面：\n",
    "1. **软硬件环境**：对评估所使用的硬件配置和软件环境进行详细说明，确保实验的可重复性。\n",
    "2. **程序运行时间精确测量**：介绍如何精确测量程序运行时间，以获取模型运行效率的准确数据。\n",
    "3. **PyTorch性能分析器**：运用PyTorch性能分析器，深入分析模型在计算过程中的性能表现。\n",
    "4. **GPU专业分析工具**：利用专业的GPU分析工具，对模型在GPU上的运行情况进行全方位的剖析。\n",
    "5. **CPU性能分析工具**：借助CPU性能分析工具，评估模型在CPU上的性能指标，为全面了解模型性能提供多维度数据支持。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 软硬件环境\n",
    "\n",
    "## 1.1 硬件资源\n",
    "**GPU：**为了较少其他应用程序的干扰，尽量关闭其他显存占用。\n",
    "\n",
    "```bash\n",
    "nvidia-smi # 查看其它使用显卡的进程 查PID\n",
    "ps aus |grep <PID> 查看进程详情\n",
    "```\n",
    "\n",
    "**CPU：** 查看CPU使用情况\n",
    "\n",
    "```bash\n",
    "htop # 查看 cpu使用情况, 核心利用情况，交换率等\n",
    "```\n",
    "\n",
    "## 1.2 设置各种随机种子\n",
    "\n",
    "**python：**因为python生态没有不能统一设置随机种子，直接看代码\n",
    "\n",
    "```python\n",
    "torch.manual_seed(seed) # 这样的设置会使 Dropout 会在相同的位置丢弃神经元\n",
    "np.random.seed(seed) # numpy\n",
    "\n",
    "random.seed(seed) # python\n",
    "# 👆这个不能完全设置随机性，随机来源很多，Hash不会因为这个设置固定\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash: 6292224222569543665\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42) # jupyter 里面每次执行结果一直，但是每次重启jupyter notebook内核，结果会变\n",
    "print(\"Hash:\", hash(\"hello\")) # \n",
    "# 解决 Hash 的随机性需要设置环境变量\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**glob 模块：**glob 模块无法保证获取的文件顺序每次都一致,如果需要保证一致性，则需要手动排序（未验证）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/fl/code/python/FGPT/01 GPT.ipynb', '/home/fl/code/python/FGPT/02 Evaluate.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# glob 随机性测试\n",
    "import glob\n",
    "import random\n",
    "# 固定种子\n",
    "random.seed(42)\n",
    "\n",
    "# 获取文件列表\n",
    "files = glob.glob(\"/home/fl/code/python/FGPT/*.ipynb\")\n",
    "\n",
    "# 打印文件列表\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU 算子：** 约束 GPU 算子随机性，GPU 的算子的随机性来源很多，比如计算精度\n",
    "\n",
    "比如结合律（A+B）\\*C 和 (A \\*C) + (B \\*C) 不一定相等\n",
    "\n",
    "又比如cuDnn 提供了多种卷积算法，默认会自动选择最优算法，这会导致卷积的结果不一致\n",
    "\n",
    "一般通过以下方式约束随机性，但是添加设置会影响 GPU 性能,仅在调试分析时使用\n",
    "\n",
    "```python\n",
    "torch.backends.cudnn.deterministic = True # 约束算子底层实现的随机性\n",
    "torch.backends.cudnn.benchmark = False # 约束 cuDnn算子随机选择算法\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，一个完整的约束随机性的步骤集合如下：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def set_seed(seed):\n",
    "    # 设置随机种子\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # 约束 GPU 算子随机性\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 限制频率\n",
    "\n",
    "**GPU 频率限制：**GPU 会根据运行状态，自动调整显存频率和基础频率\n",
    "\n",
    "GPU 锁频脚本如下(需要 GPU 的版本支持)\n",
    "\n",
    "```bash\n",
    "# 查询\n",
    "nvidia-smi --query-gpu=pstate,clocks.mem,clocks.sm,clocks.gr --format=csv\n",
    "pstate, clocks.current.memory [MHz], clocks.current.sm [MHz], clocks.current.graphics [MHz]\n",
    "P0, 6000 MHz, 1485 MHz, 1485 MHz\n",
    "# 参数解读\n",
    "# ​pstate：GPU的性能状态，范围从P0（最大性能）到P12（最小性能）。例如，P0表示GPU处于最高性能状态。\n",
    "# ​clocks.current.memory [MHz]：当前内存时钟频率，例如6000 MHz，表示显存以6000 MHz运行。\n",
    "# ​clocks.current.sm [MHz]：当前流处理器（SM）的时钟频率，例如1485 MHz，表示核心计算单元以1485 MHz运行。\n",
    "# ​clocks.current.graphics [MHz]：当前图形处理单元的时钟频率，例如1485 MHz，表示图形处理单元以1485 MHz运行。\n",
    "```\n",
    "\n",
    "```bash\n",
    "# 查询 GPU 支持的 Clock 频率组合\n",
    "nvidia-smi --query-supported-clocks=gpu_name,mem,gr --format=csv\n",
    "\n",
    "gpu_name, memory [MHz], graphics [MHz]\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2100 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2092 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2085 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2077 MHz\n",
    "# 其中mem,gr分表代表显存频率和核心频率\n",
    "````\n",
    "\n",
    "```bash\n",
    "# 设置 GPU 持久模式 0 关闭 1 开启,持久模式开启后，GPU会保持在最后一次设置的频率，而不会自动调整\n",
    "sudo nvidia-smi -pm 1\n",
    "```\n",
    "\n",
    "```bash\n",
    "\n",
    "# 固定 GPU 时钟频率\n",
    "nvidia-smi -ac xxxx,xxxx #(mermory clock, graphics clock) \n",
    "```\n",
    "\n",
    "**CPU 频率：** CPU 的性能会被划分为不同的等级称为性能状态（P-state），可以通过工具包固定 p-state 和 CPU 频率\n",
    "\n",
    "！以下暂未执行成功\n",
    "```bash\n",
    "# 安装工具班、啊、包\n",
    "sudo apt install cpufrequtils #\n",
    "# 设置环境变量\n",
    "export CPUFREQUTILS_ROOT=/usr/bin/cpufrequtils\n",
    "source /etc/profile\n",
    "cpufreq-info\n",
    "# 设置最大/最小频率\n",
    "sudo cpufreq-set -r -g performance # 设置 CPU 频率模式为 performance, -r 重新加载配置, -g 指定模式\n",
    "sudo cpufrequtils -r -d 2.4GHz -u 2.4GHz # 设置 CPU 最大/最小频率\n",
    "\n",
    "# 验证是否生效\n",
    "cpufreq-info\n",
    "\n",
    "# 或者直接查看\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_cpu_freq\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_max_freq\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_min_freq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 时间测量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算运行时间的两种方式\n",
    "- python time 模块\n",
    "- CUDA 事件计时"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 python time 模块\n",
    "\n",
    "python 有两种原生的时间测量方法，一种是 time.time()，一种是 time.perf_counter(), \n",
    "pref_counter() 准确度更高，他是微秒级别，且不受系统时间影响\n",
    "time.time() 是秒级别,表示的是自 1970 年 1 月 1 日 00:00:00 UTC 到现在的时间，受当前系统时间影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间：2.355899960093666e-05 秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "# 其他执行逻辑\n",
    "end = time.perf_counter()\n",
    "print(f\"运行时间：{end - start} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 CUDA 事件计时\n",
    "因为CPU和GPU是异步的，time.perf_counter() 的时间差表示的是 计时前后CPU的时间差。当CPU指令未等待GPU指令完成时，时间差会小于GPU指令实际运行时间。因此有两种方法解决，一种是使用同步指令，另一种是使用 CUDA 事件计时\n",
    "\n",
    "- 同步指令：torch.cuda.synchronize()，会阻塞CPU，直到GPU指令完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间：0.01255532220020541秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "size=128\n",
    "N=10\n",
    "shape =(size,size,size)\n",
    "\n",
    "x = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "y = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "\n",
    "for _ in range(N):\n",
    "    z = torch.matmul(x, y)\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "end = time.perf_counter()\n",
    "print(f\"运行时间：{(end - start) / N}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cuda 事件计时\n",
    "torch.cuda.synchronize() 执行后，最终还是在CPU端阻塞，CPU和GPU的同步过程也需要消耗时间，因此使用 cuda 事件计时，可以更准确的测量GPU指令的运行时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间：101.48966217041016 毫秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "size=128\n",
    "N=10\n",
    "shape =(size,size,size)\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "x = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "y = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "\n",
    "start.record()\n",
    "for _ in range(N):\n",
    "    z = torch.matmul(x, y)\n",
    "end.record()\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "print(f\"运行时间：{start.elapsed_time(end)} 毫秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pytorch性能分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 GPU分析工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CPU 性能分析工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
