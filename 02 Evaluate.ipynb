{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ€§èƒ½è¯„ä¼°**\n",
    "æœ¬èŠ‚å°†æ­å»ºæ€§èƒ½è¯„ä¼°ç¯å¢ƒï¼Œå¹¶å¯¹åˆå§‹æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡è¿›è¡ŒéªŒè¯ï¼ŒåŒ…æ‹¬å•å¡ååé‡ï¼ˆtokens/sï¼‰å’Œæ˜¾å­˜å ç”¨ï¼ˆGBï¼‰ç­‰ã€‚å…·ä½“æ¶µç›–ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n",
    "1. **è½¯ç¡¬ä»¶ç¯å¢ƒ**ï¼šå¯¹è¯„ä¼°æ‰€ä½¿ç”¨çš„ç¡¬ä»¶é…ç½®å’Œè½¯ä»¶ç¯å¢ƒè¿›è¡Œè¯¦ç»†è¯´æ˜ï¼Œç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§ã€‚\n",
    "2. **ç¨‹åºè¿è¡Œæ—¶é—´ç²¾ç¡®æµ‹é‡**ï¼šä»‹ç»å¦‚ä½•ç²¾ç¡®æµ‹é‡ç¨‹åºè¿è¡Œæ—¶é—´ï¼Œä»¥è·å–æ¨¡å‹è¿è¡Œæ•ˆç‡çš„å‡†ç¡®æ•°æ®ã€‚\n",
    "3. **PyTorchæ€§èƒ½åˆ†æå™¨**ï¼šè¿ç”¨PyTorchæ€§èƒ½åˆ†æå™¨ï¼Œæ·±å…¥åˆ†ææ¨¡å‹åœ¨è®¡ç®—è¿‡ç¨‹ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚\n",
    "4. **GPUä¸“ä¸šåˆ†æå·¥å…·**ï¼šåˆ©ç”¨ä¸“ä¸šçš„GPUåˆ†æå·¥å…·ï¼Œå¯¹æ¨¡å‹åœ¨GPUä¸Šçš„è¿è¡Œæƒ…å†µè¿›è¡Œå…¨æ–¹ä½çš„å‰–æã€‚\n",
    "5. **CPUæ€§èƒ½åˆ†æå·¥å…·**ï¼šå€ŸåŠ©CPUæ€§èƒ½åˆ†æå·¥å…·ï¼Œè¯„ä¼°æ¨¡å‹åœ¨CPUä¸Šçš„æ€§èƒ½æŒ‡æ ‡ï¼Œä¸ºå…¨é¢äº†è§£æ¨¡å‹æ€§èƒ½æä¾›å¤šç»´åº¦æ•°æ®æ”¯æŒã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 è½¯ç¡¬ä»¶ç¯å¢ƒ\n",
    "\n",
    "## 1.1 ç¡¬ä»¶èµ„æº\n",
    "**GPUï¼š**ä¸ºäº†è¾ƒå°‘å…¶ä»–åº”ç”¨ç¨‹åºçš„å¹²æ‰°ï¼Œå°½é‡å…³é—­å…¶ä»–æ˜¾å­˜å ç”¨ã€‚\n",
    "\n",
    "```bash\n",
    "nvidia-smi # æŸ¥çœ‹å…¶å®ƒä½¿ç”¨æ˜¾å¡çš„è¿›ç¨‹ æŸ¥PID\n",
    "ps aus |grep <PID> æŸ¥çœ‹è¿›ç¨‹è¯¦æƒ…\n",
    "```\n",
    "\n",
    "**CPUï¼š** æŸ¥çœ‹CPUä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "```bash\n",
    "htop # æŸ¥çœ‹ cpuä½¿ç”¨æƒ…å†µ, æ ¸å¿ƒåˆ©ç”¨æƒ…å†µï¼Œäº¤æ¢ç‡ç­‰\n",
    "```\n",
    "\n",
    "## 1.2 è®¾ç½®å„ç§éšæœºç§å­\n",
    "\n",
    "**pythonï¼š**å› ä¸ºpythonç”Ÿæ€æ²¡æœ‰ä¸èƒ½ç»Ÿä¸€è®¾ç½®éšæœºç§å­ï¼Œç›´æ¥çœ‹ä»£ç \n",
    "\n",
    "```python\n",
    "torch.manual_seed(seed) # è¿™æ ·çš„è®¾ç½®ä¼šä½¿ Dropout ä¼šåœ¨ç›¸åŒçš„ä½ç½®ä¸¢å¼ƒç¥ç»å…ƒ\n",
    "np.random.seed(seed) # numpy\n",
    "\n",
    "random.seed(seed) # python\n",
    "# ğŸ‘†è¿™ä¸ªä¸èƒ½å®Œå…¨è®¾ç½®éšæœºæ€§ï¼Œéšæœºæ¥æºå¾ˆå¤šï¼ŒHashä¸ä¼šå› ä¸ºè¿™ä¸ªè®¾ç½®å›ºå®š\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash: 6292224222569543665\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42) # jupyter é‡Œé¢æ¯æ¬¡æ‰§è¡Œç»“æœä¸€ç›´ï¼Œä½†æ˜¯æ¯æ¬¡é‡å¯jupyter notebookå†…æ ¸ï¼Œç»“æœä¼šå˜\n",
    "print(\"Hash:\", hash(\"hello\")) # \n",
    "# è§£å†³ Hash çš„éšæœºæ€§éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**glob æ¨¡å—ï¼š**glob æ¨¡å—æ— æ³•ä¿è¯è·å–çš„æ–‡ä»¶é¡ºåºæ¯æ¬¡éƒ½ä¸€è‡´,å¦‚æœéœ€è¦ä¿è¯ä¸€è‡´æ€§ï¼Œåˆ™éœ€è¦æ‰‹åŠ¨æ’åºï¼ˆæœªéªŒè¯ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/fl/code/python/FGPT/01 GPT.ipynb', '/home/fl/code/python/FGPT/02 Evaluate.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# glob éšæœºæ€§æµ‹è¯•\n",
    "import glob\n",
    "import random\n",
    "# å›ºå®šç§å­\n",
    "random.seed(42)\n",
    "\n",
    "# è·å–æ–‡ä»¶åˆ—è¡¨\n",
    "files = glob.glob(\"/home/fl/code/python/FGPT/*.ipynb\")\n",
    "\n",
    "# æ‰“å°æ–‡ä»¶åˆ—è¡¨\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU ç®—å­ï¼š** çº¦æŸ GPU ç®—å­éšæœºæ€§ï¼ŒGPU çš„ç®—å­çš„éšæœºæ€§æ¥æºå¾ˆå¤šï¼Œæ¯”å¦‚è®¡ç®—ç²¾åº¦\n",
    "\n",
    "æ¯”å¦‚ç»“åˆå¾‹ï¼ˆA+Bï¼‰\\*C å’Œ (A \\*C) + (B \\*C) ä¸ä¸€å®šç›¸ç­‰\n",
    "\n",
    "åˆæ¯”å¦‚cuDnn æä¾›äº†å¤šç§å·ç§¯ç®—æ³•ï¼Œé»˜è®¤ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•ï¼Œè¿™ä¼šå¯¼è‡´å·ç§¯çš„ç»“æœä¸ä¸€è‡´\n",
    "\n",
    "ä¸€èˆ¬é€šè¿‡ä»¥ä¸‹æ–¹å¼çº¦æŸéšæœºæ€§ï¼Œä½†æ˜¯æ·»åŠ è®¾ç½®ä¼šå½±å“ GPU æ€§èƒ½,ä»…åœ¨è°ƒè¯•åˆ†ææ—¶ä½¿ç”¨\n",
    "\n",
    "```python\n",
    "torch.backends.cudnn.deterministic = True # çº¦æŸç®—å­åº•å±‚å®ç°çš„éšæœºæ€§\n",
    "torch.backends.cudnn.benchmark = False # çº¦æŸ cuDnnç®—å­éšæœºé€‰æ‹©ç®—æ³•\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç»¼ä¸Šï¼Œä¸€ä¸ªå®Œæ•´çš„çº¦æŸéšæœºæ€§çš„æ­¥éª¤é›†åˆå¦‚ä¸‹ï¼š\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def set_seed(seed):\n",
    "    # è®¾ç½®éšæœºç§å­\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # çº¦æŸ GPU ç®—å­éšæœºæ€§\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 é™åˆ¶é¢‘ç‡\n",
    "\n",
    "**GPU é¢‘ç‡é™åˆ¶ï¼š**GPU ä¼šæ ¹æ®è¿è¡ŒçŠ¶æ€ï¼Œè‡ªåŠ¨è°ƒæ•´æ˜¾å­˜é¢‘ç‡å’ŒåŸºç¡€é¢‘ç‡\n",
    "\n",
    "GPU é”é¢‘è„šæœ¬å¦‚ä¸‹(éœ€è¦ GPU çš„ç‰ˆæœ¬æ”¯æŒ)\n",
    "\n",
    "```bash\n",
    "# æŸ¥è¯¢\n",
    "nvidia-smi --query-gpu=pstate,clocks.mem,clocks.sm,clocks.gr --format=csv\n",
    "pstate, clocks.current.memory [MHz], clocks.current.sm [MHz], clocks.current.graphics [MHz]\n",
    "P0, 6000 MHz, 1485 MHz, 1485 MHz\n",
    "# å‚æ•°è§£è¯»\n",
    "# â€‹pstateï¼šGPUçš„æ€§èƒ½çŠ¶æ€ï¼ŒèŒƒå›´ä»P0ï¼ˆæœ€å¤§æ€§èƒ½ï¼‰åˆ°P12ï¼ˆæœ€å°æ€§èƒ½ï¼‰ã€‚ä¾‹å¦‚ï¼ŒP0è¡¨ç¤ºGPUå¤„äºæœ€é«˜æ€§èƒ½çŠ¶æ€ã€‚\n",
    "# â€‹clocks.current.memory [MHz]ï¼šå½“å‰å†…å­˜æ—¶é’Ÿé¢‘ç‡ï¼Œä¾‹å¦‚6000 MHzï¼Œè¡¨ç¤ºæ˜¾å­˜ä»¥6000 MHzè¿è¡Œã€‚\n",
    "# â€‹clocks.current.sm [MHz]ï¼šå½“å‰æµå¤„ç†å™¨ï¼ˆSMï¼‰çš„æ—¶é’Ÿé¢‘ç‡ï¼Œä¾‹å¦‚1485 MHzï¼Œè¡¨ç¤ºæ ¸å¿ƒè®¡ç®—å•å…ƒä»¥1485 MHzè¿è¡Œã€‚\n",
    "# â€‹clocks.current.graphics [MHz]ï¼šå½“å‰å›¾å½¢å¤„ç†å•å…ƒçš„æ—¶é’Ÿé¢‘ç‡ï¼Œä¾‹å¦‚1485 MHzï¼Œè¡¨ç¤ºå›¾å½¢å¤„ç†å•å…ƒä»¥1485 MHzè¿è¡Œã€‚\n",
    "```\n",
    "\n",
    "```bash\n",
    "# æŸ¥è¯¢ GPU æ”¯æŒçš„ Clock é¢‘ç‡ç»„åˆ\n",
    "nvidia-smi --query-supported-clocks=gpu_name,mem,gr --format=csv\n",
    "\n",
    "gpu_name, memory [MHz], graphics [MHz]\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2100 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2092 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2085 MHz\n",
    "NVIDIA GeForce RTX 3050 Ti Laptop GPU, 6001 MHz, 2077 MHz\n",
    "# å…¶ä¸­mem,gråˆ†è¡¨ä»£è¡¨æ˜¾å­˜é¢‘ç‡å’Œæ ¸å¿ƒé¢‘ç‡\n",
    "````\n",
    "\n",
    "```bash\n",
    "# è®¾ç½® GPU æŒä¹…æ¨¡å¼ 0 å…³é—­ 1 å¼€å¯,æŒä¹…æ¨¡å¼å¼€å¯åï¼ŒGPUä¼šä¿æŒåœ¨æœ€åä¸€æ¬¡è®¾ç½®çš„é¢‘ç‡ï¼Œè€Œä¸ä¼šè‡ªåŠ¨è°ƒæ•´\n",
    "sudo nvidia-smi -pm 1\n",
    "```\n",
    "\n",
    "```bash\n",
    "\n",
    "# å›ºå®š GPU æ—¶é’Ÿé¢‘ç‡\n",
    "nvidia-smi -ac xxxx,xxxx #(mermory clock, graphics clock) \n",
    "```\n",
    "\n",
    "**CPU é¢‘ç‡ï¼š** CPU çš„æ€§èƒ½ä¼šè¢«åˆ’åˆ†ä¸ºä¸åŒçš„ç­‰çº§ç§°ä¸ºæ€§èƒ½çŠ¶æ€ï¼ˆP-stateï¼‰ï¼Œå¯ä»¥é€šè¿‡å·¥å…·åŒ…å›ºå®š p-state å’Œ CPU é¢‘ç‡\n",
    "\n",
    "ï¼ä»¥ä¸‹æš‚æœªæ‰§è¡ŒæˆåŠŸ\n",
    "```bash\n",
    "# å®‰è£…å·¥å…·ç­ã€å•Šã€åŒ…\n",
    "sudo apt install cpufrequtils #\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "export CPUFREQUTILS_ROOT=/usr/bin/cpufrequtils\n",
    "source /etc/profile\n",
    "cpufreq-info\n",
    "# è®¾ç½®æœ€å¤§/æœ€å°é¢‘ç‡\n",
    "sudo cpufreq-set -r -g performance # è®¾ç½® CPU é¢‘ç‡æ¨¡å¼ä¸º performance, -r é‡æ–°åŠ è½½é…ç½®, -g æŒ‡å®šæ¨¡å¼\n",
    "sudo cpufrequtils -r -d 2.4GHz -u 2.4GHz # è®¾ç½® CPU æœ€å¤§/æœ€å°é¢‘ç‡\n",
    "\n",
    "# éªŒè¯æ˜¯å¦ç”Ÿæ•ˆ\n",
    "cpufreq-info\n",
    "\n",
    "# æˆ–è€…ç›´æ¥æŸ¥çœ‹\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_cpu_freq\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_max_freq\n",
    "cat /sys/device/system/cpu/cpu0/cpufreq/scaling_min_freq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 æ—¶é—´æµ‹é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®¡ç®—è¿è¡Œæ—¶é—´çš„ä¸¤ç§æ–¹å¼\n",
    "- python time æ¨¡å—\n",
    "- CUDA äº‹ä»¶è®¡æ—¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 python time æ¨¡å—\n",
    "\n",
    "python æœ‰ä¸¤ç§åŸç”Ÿçš„æ—¶é—´æµ‹é‡æ–¹æ³•ï¼Œä¸€ç§æ˜¯ time.time()ï¼Œä¸€ç§æ˜¯ time.perf_counter(), \n",
    "pref_counter() å‡†ç¡®åº¦æ›´é«˜ï¼Œä»–æ˜¯å¾®ç§’çº§åˆ«ï¼Œä¸”ä¸å—ç³»ç»Ÿæ—¶é—´å½±å“\n",
    "time.time() æ˜¯ç§’çº§åˆ«,è¡¨ç¤ºçš„æ˜¯è‡ª 1970 å¹´ 1 æœˆ 1 æ—¥ 00:00:00 UTC åˆ°ç°åœ¨çš„æ—¶é—´ï¼Œå—å½“å‰ç³»ç»Ÿæ—¶é—´å½±å“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿è¡Œæ—¶é—´ï¼š2.355899960093666e-05 ç§’\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "# å…¶ä»–æ‰§è¡Œé€»è¾‘\n",
    "end = time.perf_counter()\n",
    "print(f\"è¿è¡Œæ—¶é—´ï¼š{end - start} ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 CUDA äº‹ä»¶è®¡æ—¶\n",
    "å› ä¸ºCPUå’ŒGPUæ˜¯å¼‚æ­¥çš„ï¼Œtime.perf_counter() çš„æ—¶é—´å·®è¡¨ç¤ºçš„æ˜¯ è®¡æ—¶å‰åCPUçš„æ—¶é—´å·®ã€‚å½“CPUæŒ‡ä»¤æœªç­‰å¾…GPUæŒ‡ä»¤å®Œæˆæ—¶ï¼Œæ—¶é—´å·®ä¼šå°äºGPUæŒ‡ä»¤å®é™…è¿è¡Œæ—¶é—´ã€‚å› æ­¤æœ‰ä¸¤ç§æ–¹æ³•è§£å†³ï¼Œä¸€ç§æ˜¯ä½¿ç”¨åŒæ­¥æŒ‡ä»¤ï¼Œå¦ä¸€ç§æ˜¯ä½¿ç”¨ CUDA äº‹ä»¶è®¡æ—¶\n",
    "\n",
    "- åŒæ­¥æŒ‡ä»¤ï¼štorch.cuda.synchronize()ï¼Œä¼šé˜»å¡CPUï¼Œç›´åˆ°GPUæŒ‡ä»¤å®Œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿è¡Œæ—¶é—´ï¼š0.01255532220020541ç§’\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "size=128\n",
    "N=10\n",
    "shape =(size,size,size)\n",
    "\n",
    "x = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "y = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "\n",
    "for _ in range(N):\n",
    "    z = torch.matmul(x, y)\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "end = time.perf_counter()\n",
    "print(f\"è¿è¡Œæ—¶é—´ï¼š{(end - start) / N}ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cuda äº‹ä»¶è®¡æ—¶\n",
    "torch.cuda.synchronize() æ‰§è¡Œåï¼Œæœ€ç»ˆè¿˜æ˜¯åœ¨CPUç«¯é˜»å¡ï¼ŒCPUå’ŒGPUçš„åŒæ­¥è¿‡ç¨‹ä¹Ÿéœ€è¦æ¶ˆè€—æ—¶é—´ï¼Œå› æ­¤ä½¿ç”¨ cuda äº‹ä»¶è®¡æ—¶ï¼Œå¯ä»¥æ›´å‡†ç¡®çš„æµ‹é‡GPUæŒ‡ä»¤çš„è¿è¡Œæ—¶é—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿è¡Œæ—¶é—´ï¼š101.48966217041016 æ¯«ç§’\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "size=128\n",
    "N=10\n",
    "shape =(size,size,size)\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "x = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "y = torch.randn(dtype=torch.float, size=shape, device='cuda')\n",
    "\n",
    "start.record()\n",
    "for _ in range(N):\n",
    "    z = torch.matmul(x, y)\n",
    "end.record()\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "print(f\"è¿è¡Œæ—¶é—´ï¼š{start.elapsed_time(end)} æ¯«ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pytorchæ€§èƒ½åˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 GPUåˆ†æå·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CPU æ€§èƒ½åˆ†æå·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
