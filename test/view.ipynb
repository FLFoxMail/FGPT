{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view() 方法测试\n",
    "\n",
    "代码段1\n",
    "\n",
    "```python\n",
    "y = torch.matmul(attention_weights, V)  # [batch_size * seq_len, num_heads, d_v]\n",
    "y = y.view(-1, self.num_heads * self.d_v)  # [batch_size * seq_len, d_v * num_heads]\n",
    "y = self.W(y)  # 全连接层输入维度为 d_v*num_heads → d_model\n",
    "y = y.view(-1, x.size(1), self.d_model)  # 恢复为 [batch_size, seq_len, d_model]\n",
    "```\n",
    "\n",
    "代码段 2\n",
    "\n",
    "```python\n",
    "y = torch.matmul(attention_weights, V)  # [batch_size * seq_len, num_heads, d_v]\n",
    "y = y.view(-1, seq_len, self.num_heads * self.d_v)  # [batch_size, seq_len, d_v*num_heads]\n",
    "y = self.W(y)  # 全连接层输入维度为 d_v*num_heads → d_model\n",
    "```\n",
    "这两段代码的输出形状数值是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状是否相同: True\n",
      "数值差异是否接近零: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 参数设置\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "num_heads = 4\n",
    "d_v = 8\n",
    "d_model = 32\n",
    "\n",
    "# 初始化相同的权重（确保公平比较）\n",
    "torch.manual_seed(42)\n",
    "W = nn.Linear(num_heads * d_v, d_model)\n",
    "\n",
    "# 模拟输入（假设 attention_weights 和 V 已计算）\n",
    "attention_weights = torch.randn(batch_size * seq_len, num_heads, num_heads)\n",
    "V = torch.randn(batch_size * seq_len, num_heads, d_v)\n",
    "\n",
    "# 第一段代码\n",
    "def code1():\n",
    "    y1 = torch.matmul(attention_weights, V)\n",
    "    y1 = y1.view(-1, num_heads * d_v)\n",
    "    y1 = W(y1)\n",
    "    y1 = y1.view(-1, seq_len, d_model)\n",
    "    return y1\n",
    "\n",
    "# 第二段代码\n",
    "def code2():\n",
    "    y2 = torch.matmul(attention_weights, V)\n",
    "    y2 = y2.view(-1, seq_len, num_heads * d_v)\n",
    "    y2 = W(y2)\n",
    "    return y2\n",
    "\n",
    "# 运行并比较结果\n",
    "output1 = code1()\n",
    "output2 = code2()\n",
    "\n",
    "# 检查形状和数值是否一致\n",
    "print(\"形状是否相同:\", output1.shape == output2.shape)  # 输出: True\n",
    "print(\"数值差异是否接近零:\", torch.allclose(output1, output2, atol=1e-6))  # 输出: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7882, 0.3674, 0.0208, 0.4562],\n",
       "         [0.8598, 0.1526, 0.0218, 0.6150],\n",
       "         [0.7079, 0.4024, 0.5637, 0.2014]],\n",
       "\n",
       "        [[0.5853, 0.0600, 0.5856, 0.4186],\n",
       "         [0.6840, 0.4798, 0.1205, 0.2950],\n",
       "         [0.7061, 0.8781, 0.9906, 0.3617]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = np.random.rand(2, 3, 4)\n",
    "# flip 沿着第 0 轴进行翻转\n",
    "y = np.flip(x, axis=0)\n",
    "y_copy = y.copy()\n",
    "torch.from_numpy(y_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
